{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeea1e8a-ab0a-445d-8843-72bbf1dce41a",
   "metadata": {},
   "source": [
    "## The Hetionet data contains the source node and a target node with the kind of relation that exist between them. let's start by extracting the nodes IDs for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "57e12e27-086b-497f-9c13-84980688d7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>metaedge</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gene::9021</td>\n",
       "      <td>GpBP</td>\n",
       "      <td>Biological Process::GO:0071357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gene::51676</td>\n",
       "      <td>GpBP</td>\n",
       "      <td>Biological Process::GO:0098780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gene::19</td>\n",
       "      <td>GpBP</td>\n",
       "      <td>Biological Process::GO:0055088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gene::3176</td>\n",
       "      <td>GpBP</td>\n",
       "      <td>Biological Process::GO:0010243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gene::3039</td>\n",
       "      <td>GpBP</td>\n",
       "      <td>Biological Process::GO:0006898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source metaedge                          target\n",
       "0   Gene::9021     GpBP  Biological Process::GO:0071357\n",
       "1  Gene::51676     GpBP  Biological Process::GO:0098780\n",
       "2     Gene::19     GpBP  Biological Process::GO:0055088\n",
       "3   Gene::3176     GpBP  Biological Process::GO:0010243\n",
       "4   Gene::3039     GpBP  Biological Process::GO:0006898"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#edge_data[\"source\"] = edge_data[\"source\"].str.split(\"::\", expand = True)[1]\n",
    "#edge_data[\"target\"] = edge_data[\"target\"].str.split(\"::\", expand=True)[1]\n",
    "edge_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77819b9e-7061-4621-a3e9-f47fc8e23411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def create_entity_relation_dicts_from_df(data_path, triples_df):\n",
    "    entity_set = set(triples_df['source']).union(set(triples_df['target']))\n",
    "    relation_set = set(triples_df['metaedge'])\n",
    "\n",
    "    entity2id = {entity: idx for idx, entity in enumerate(entity_set)}\n",
    "    relation2id = {relation: idx for idx, relation in enumerate(relation_set)}\n",
    "\n",
    "    with open(os.path.join(data_path, 'entities.dict'), 'w') as fout:\n",
    "        for entity, idx in entity2id.items():\n",
    "            fout.write(f\"{idx}\\t{entity}\\n\")\n",
    "\n",
    "    with open(os.path.join(data_path, 'relations.dict'), 'w') as fout:\n",
    "        for relation, idx in relation2id.items():\n",
    "            fout.write(f\"{idx}\\t{relation}\\n\")\n",
    "\n",
    "    return entity2id, relation2id\n",
    "\n",
    "# Example usage:\n",
    "data_path = 'data/FB15k'\n",
    "triples_df = pd.read_csv(\"data/FB15k/hetionet-v1.0-edges.sif\", delimiter=\"\\t\")\n",
    "entity2id, relation2id = create_entity_relation_dicts_from_df(data_path, triples_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e731146-72b7-4509-9b5b-3bcf7c5b6fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_data, test_data = train_test_split(edge_data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to save DataFrame to a text file\n",
    "def save_to_text_file(df, file_name):\n",
    "    df.to_csv(file_name, sep='\\t', index=False, header = False)\n",
    "\n",
    "# Save train, validation, and test datasets to text files\n",
    "path = \"data/FB15k/\"\n",
    "save_to_text_file(train_data, path + 'train.txt')\n",
    "save_to_text_file(val_data, path + 'valid.txt')\n",
    "save_to_text_file(test_data, path + 'test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1968e-f160-4df8-95b7-d938376d14b2",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25ef74-346f-47ac-9c93-628247f31015",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5783e09f-fbd0-49fc-a3e8-47b19a19f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 47031\n",
      "Number of unique node types: 11\n",
      "----------------------------------------\n",
      "Anatomy\n",
      "Biological Process\n",
      "Cellular Component\n",
      "Compound\n",
      "Disease\n",
      "Gene\n",
      "Molecular Function\n",
      "Pathway\n",
      "Pharmacologic Class\n",
      "Side Effect\n",
      "Symptom\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of nodes: {len(node_data)}\")\n",
    "print(\"Number of unique node types: {}\".format(len(node_data[\"kind\"].unique())))\n",
    "print(\"-\"*40)\n",
    "for node_type in node_data[\"kind\"].unique():\n",
    "    print(node_type)\n",
    "print(\"-\"*40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20ac2e-14d3-4b87-a923-be668a7258a5",
   "metadata": {},
   "source": [
    "# Convert dataset to tripples format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f2623c8-646a-40ea-950b-7fd27fc1dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import KGEModel\n",
    "from dataloader import TrainDataset, BidirectionalOneShotIterator\n",
    "\n",
    "# Define all functions from your script\n",
    "# Including: override_config, save_model, read_triple, set_logger, log_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fefb32-dc45-4b7f-801a-69bcfdf4b2be",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3be68b3a-868d-414f-afba-147314ee6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cuda = True\n",
    "        self.do_train = True\n",
    "        self.do_valid = True\n",
    "        self.do_test = True\n",
    "        self.evaluate_train = False\n",
    "        self.countries = False\n",
    "        self.regions = None\n",
    "        self.data_path = 'data/FB15k'\n",
    "        self.model = 'TransE'\n",
    "        self.double_entity_embedding = False\n",
    "        self.double_relation_embedding = False\n",
    "        self.negative_sample_size = 128\n",
    "        self.hidden_dim = 200\n",
    "        self.gamma = 12.0\n",
    "        self.negative_adversarial_sampling = False\n",
    "        self.adversarial_temperature = 1.0\n",
    "        self.batch_size = 1024\n",
    "        self.regularization = 0.0\n",
    "        self.test_batch_size = 4\n",
    "        self.uni_weight = False\n",
    "        self.learning_rate = 0.0001\n",
    "        self.cpu_num = 10\n",
    "        self.init_checkpoint = None\n",
    "        self.save_path = 'models/TransE_FB15k'\n",
    "        self.max_steps = 10000\n",
    "        self.warm_up_steps = None\n",
    "        self.save_checkpoint_steps = 1000\n",
    "        self.valid_steps = 1000\n",
    "        self.log_steps = 100\n",
    "        self.test_log_steps = 1000\n",
    "        self.nentity = 0\n",
    "        self.nrelation = 0\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab04fe9-2398-4f47-9585-259302d8db01",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7800c241-8b58-4649-aa82-b9ee270719e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    #Argument validation and innitialization\n",
    "    if (not args.do_train) and (not args.do_valid) and (not args.do_test):\n",
    "        raise ValueError('One of train/val/test mode must be chosen.')\n",
    "    \n",
    "    if args.init_checkpoint:\n",
    "        override_config(args)\n",
    "    elif args.data_path is None:\n",
    "        raise ValueError('One of init_checkpoint/data_path must be chosen.')\n",
    "\n",
    "    if args.do_train and args.save_path is None:\n",
    "        raise ValueError('Where do you want to save your trained model?')\n",
    "    \n",
    "    if args.save_path and not os.path.exists(args.save_path):\n",
    "        os.makedirs(args.save_path)\n",
    "    \n",
    "    set_logger(args) #Logger settup\n",
    "    \n",
    "    #load entity dictionary\n",
    "    with open(os.path.join(args.data_path, 'entities.dict')) as fin:\n",
    "        entity2id = dict()\n",
    "        for line in fin:\n",
    "            eid, entity = line.strip().split('\\t')\n",
    "            entity2id[entity] = int(eid)\n",
    "\n",
    "    #load relation dictionary\n",
    "    with open(os.path.join(args.data_path, 'relations.dict')) as fin:\n",
    "        relation2id = dict()\n",
    "        for line in fin:\n",
    "            rid, relation = line.strip().split('\\t')\n",
    "            relation2id[relation] = int(rid)\n",
    "    \n",
    "    if args.countries:\n",
    "        regions = list()\n",
    "        with open(os.path.join(args.data_path, 'regions.list')) as fin:\n",
    "            for line in fin:\n",
    "                region = line.strip()\n",
    "                regions.append(entity2id[region])\n",
    "        args.regions = regions\n",
    "\n",
    "    #set entity and relations\n",
    "    nentity = len(entity2id)\n",
    "    nrelation = len(relation2id)\n",
    "    \n",
    "    args.nentity = nentity\n",
    "    args.nrelation = nrelation\n",
    "\n",
    "    #Log basic information\n",
    "    logging.info('Model: %s' % args.model)\n",
    "    logging.info('Data Path: %s' % args.data_path)\n",
    "    logging.info('#entity: %d' % nentity)\n",
    "    logging.info('#relation: %d' % nrelation)\n",
    "\n",
    "    #Load the triples\n",
    "    train_triples = read_triple(os.path.join(args.data_path, 'train.txt'), entity2id, relation2id)\n",
    "    logging.info('#train: %d' % len(train_triples))\n",
    "    valid_triples = read_triple(os.path.join(args.data_path, 'valid.txt'), entity2id, relation2id)\n",
    "    logging.info('#valid: %d' % len(valid_triples))\n",
    "    test_triples = read_triple(os.path.join(args.data_path, 'test.txt'), entity2id, relation2id)\n",
    "    logging.info('#test: %d' % len(test_triples))\n",
    "    \n",
    "    all_true_triples = train_triples + valid_triples + test_triples\n",
    "\n",
    "    #Innitialise the model\n",
    "    kge_model = KGEModel(\n",
    "        model_name=args.model,\n",
    "        nentity=nentity,\n",
    "        nrelation=nrelation,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        gamma=args.gamma,\n",
    "        double_entity_embedding=args.double_entity_embedding,\n",
    "        double_relation_embedding=args.double_relation_embedding\n",
    "    )\n",
    "\n",
    "    #Log model parameters\n",
    "    logging.info('Model Parameter Configuration:')\n",
    "    for name, param in kge_model.named_parameters():\n",
    "        logging.info('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\n",
    "\n",
    "    #Use GPU support \n",
    "    if args.cuda:\n",
    "        kge_model = kge_model.cuda()\n",
    "\n",
    "    #Trainingn preparation\n",
    "    if args.do_train:\n",
    "        # Set training dataloader iterator\n",
    "        train_dataloader_head = DataLoader(\n",
    "            TrainDataset(train_triples, nentity, nrelation, args.negative_sample_size, 'head-batch'), \n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True, \n",
    "            num_workers=max(1, args.cpu_num//2),\n",
    "            collate_fn=TrainDataset.collate_fn\n",
    "        )\n",
    "        \n",
    "        train_dataloader_tail = DataLoader(\n",
    "            TrainDataset(train_triples, nentity, nrelation, args.negative_sample_size, 'tail-batch'), \n",
    "            batch_size=args.batch_size,\n",
    "            shuffle=True, \n",
    "            num_workers=max(1, args.cpu_num//2),\n",
    "            collate_fn=TrainDataset.collate_fn\n",
    "        )\n",
    "        \n",
    "        train_iterator = BidirectionalOneShotIterator(train_dataloader_head, train_dataloader_tail)\n",
    "        \n",
    "        # Set training configuration\n",
    "        current_learning_rate = args.learning_rate\n",
    "        optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()), \n",
    "            lr=current_learning_rate\n",
    "        )\n",
    "        if args.warm_up_steps:\n",
    "            warm_up_steps = args.warm_up_steps\n",
    "        else:\n",
    "            warm_up_steps = args.max_steps // 2\n",
    "\n",
    "    #Checkpoint loading\n",
    "    if args.init_checkpoint:\n",
    "        # Restore model from checkpoint directory\n",
    "        logging.info('Loading checkpoint %s...' % args.init_checkpoint)\n",
    "        checkpoint = torch.load(os.path.join(args.init_checkpoint, 'checkpoint'))\n",
    "        init_step = checkpoint['step']\n",
    "        kge_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if args.do_train:\n",
    "            current_learning_rate = checkpoint['current_learning_rate']\n",
    "            warm_up_steps = checkpoint['warm_up_steps']\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    else:\n",
    "        logging.info('Randomly Initializing %s Model...' % args.model)\n",
    "        init_step = 0\n",
    "\n",
    "    #Training loop\n",
    "    step = init_step\n",
    "    \n",
    "    logging.info('Start Training...')\n",
    "    logging.info('init_step = %d' % init_step)\n",
    "    logging.info('batch_size = %d' % args.batch_size)\n",
    "    logging.info('negative_adversarial_sampling = %d' % args.negative_adversarial_sampling)\n",
    "    logging.info('hidden_dim = %d' % args.hidden_dim)\n",
    "    logging.info('gamma = %f' % args.gamma)\n",
    "    logging.info('negative_adversarial_sampling = %s' % str(args.negative_adversarial_sampling))\n",
    "    if args.negative_adversarial_sampling:\n",
    "        logging.info('adversarial_temperature = %f' % args.adversarial_temperature)\n",
    "    \n",
    "    # Set valid dataloader as it would be evaluated during training\n",
    "    if args.do_train:\n",
    "        logging.info('learning_rate = %d' % current_learning_rate)\n",
    "\n",
    "        training_logs = []\n",
    "        \n",
    "        #Training Loop\n",
    "        for step in range(init_step, args.max_steps):\n",
    "            \n",
    "            log = kge_model.train_step(kge_model, optimizer, train_iterator, args)\n",
    "            \n",
    "            training_logs.append(log)\n",
    "            \n",
    "            if step >= warm_up_steps:\n",
    "                current_learning_rate = current_learning_rate / 10\n",
    "                logging.info('Change learning_rate to %f at step %d' % (current_learning_rate, step))\n",
    "                optimizer = torch.optim.Adam(\n",
    "                    filter(lambda p: p.requires_grad, kge_model.parameters()), \n",
    "                    lr=current_learning_rate\n",
    "                )\n",
    "                warm_up_steps = warm_up_steps * 3\n",
    "            \n",
    "            if step % args.save_checkpoint_steps == 0:\n",
    "                save_variable_list = {\n",
    "                    'step': step, \n",
    "                    'current_learning_rate': current_learning_rate,\n",
    "                    'warm_up_steps': warm_up_steps\n",
    "                }\n",
    "                save_model(kge_model, optimizer, save_variable_list, args)\n",
    "                \n",
    "            if step % args.log_steps == 0:\n",
    "                metrics = {}\n",
    "                for metric in training_logs[0].keys():\n",
    "                    metrics[metric] = sum([log[metric] for log in training_logs])/len(training_logs)\n",
    "                log_metrics('Training average', step, metrics)\n",
    "                training_logs = []\n",
    "                \n",
    "            if args.do_valid and step % args.valid_steps == 0:\n",
    "                logging.info('Evaluating on Valid Dataset...')\n",
    "                metrics = kge_model.test_step(kge_model, valid_triples, all_true_triples, args)\n",
    "                log_metrics('Valid', step, metrics)\n",
    "        \n",
    "        save_variable_list = {\n",
    "            'step': step, \n",
    "            'current_learning_rate': current_learning_rate,\n",
    "            'warm_up_steps': warm_up_steps\n",
    "        }\n",
    "        save_model(kge_model, optimizer, save_variable_list, args)\n",
    "        \n",
    "    if args.do_valid:\n",
    "        logging.info('Evaluating on Valid Dataset...')\n",
    "        metrics = kge_model.test_step(kge_model, valid_triples, all_true_triples, args)\n",
    "        log_metrics('Valid', step, metrics)\n",
    "    \n",
    "    if args.do_test:\n",
    "        logging.info('Evaluating on Test Dataset...')\n",
    "        metrics = kge_model.test_step(kge_model, test_triples, all_true_triples, args)\n",
    "        log_metrics('Test', step, metrics)\n",
    "    \n",
    "    if args.evaluate_train:\n",
    "        logging.info('Evaluating on Training Dataset...')\n",
    "        metrics = kge_model.test_step(kge_model, train_triples, all_true_triples, args)\n",
    "        log_metrics('Test', step, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80a25e75-0af5-44d8-a82b-692159b849e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 13:53:10,812 Model: TransE\n",
      "2024-05-20 13:53:10,816 Data Path: data/FB15k\n",
      "2024-05-20 13:53:10,820 #entity: 0\n",
      "2024-05-20 13:53:10,822 #relation: 0\n",
      "2024-05-20 13:53:10,828 #train: 0\n",
      "2024-05-20 13:53:10,846 #valid: 0\n",
      "2024-05-20 13:53:10,848 #test: 0\n",
      "2024-05-20 13:53:12,759 Model Parameter Configuration:\n",
      "2024-05-20 13:53:12,806 Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2024-05-20 13:53:12,817 Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2024-05-20 13:53:12,846 Parameter entity_embedding: torch.Size([0, 200]), require_grad = True\n",
      "2024-05-20 13:53:12,851 Parameter relation_embedding: torch.Size([0, 200]), require_grad = True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m args \u001b[38;5;241m=\u001b[39m Args()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Run the main function with these arguments\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 73\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     70\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, require_grad = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (name, \u001b[38;5;28mstr\u001b[39m(param\u001b[38;5;241m.\u001b[39msize()), \u001b[38;5;28mstr\u001b[39m(param\u001b[38;5;241m.\u001b[39mrequires_grad)))\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mcuda:\n\u001b[1;32m---> 73\u001b[0m     kge_model \u001b[38;5;241m=\u001b[39m \u001b[43mkge_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdo_train:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Set training dataloader iterator\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     train_dataloader_head \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     78\u001b[0m         TrainDataset(train_triples, nentity, nrelation, args\u001b[38;5;241m.\u001b[39mnegative_sample_size, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead-batch\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[0;32m     79\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m         collate_fn\u001b[38;5;241m=\u001b[39mTrainDataset\u001b[38;5;241m.\u001b[39mcollate_fn\n\u001b[0;32m     83\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:918\u001b[0m, in \u001b[0;36mModule.cuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:918\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\cuda\\__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Initialize the argument class\n",
    "args = Args()\n",
    "\n",
    "# Run the main function with these arguments\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ad33eab-2bbb-41c2-92ba-c0db1c400347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming model and dataloader are your custom modules\n",
    "from model import KGEModel\n",
    "from dataloader import TrainDataset, BidirectionalOneShotIterator\n",
    "\n",
    "def override_config(args):\n",
    "    # Implement the logic to override config based on checkpoint\n",
    "    pass\n",
    "\n",
    "def save_model(model, optimizer, save_variable_list, args):\n",
    "    # Implement the logic to save the model\n",
    "    pass\n",
    "\n",
    "def read_triple(file_path, entity2id, relation2id):\n",
    "    triples = []\n",
    "    with open(file_path) as fin:\n",
    "        for line in fin:\n",
    "            head, relation, tail = line.strip().split('\\t')\n",
    "            triples.append((entity2id[head], relation2id[relation], entity2id[tail]))\n",
    "    return triples\n",
    "\n",
    "def set_logger(args):\n",
    "    log_file = os.path.join(args.save_path or args.init_checkpoint, 'train.log')\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s %(message)s',\n",
    "        level=logging.INFO,\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def log_metrics(mode, step, metrics):\n",
    "    for metric in metrics:\n",
    "        logging.info('%s %s at step %d: %f' % (mode, metric, step, metrics[metric]))\n",
    "\n",
    "# Define any other necessary helper functions from your script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364981f0-4dfd-4604-9f87-1dd415f5d6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 20:16:50,672 Model: TransE\n",
      "2024-05-30 20:16:50,704 Data Path: data/FB15k\n",
      "2024-05-30 20:16:50,704 #entity: 45158\n",
      "2024-05-30 20:16:50,704 #relation: 24\n",
      "2024-05-30 20:16:53,673 #train: 1440125\n",
      "2024-05-30 20:16:54,536 #valid: 360032\n",
      "2024-05-30 20:16:55,526 #test: 450040\n",
      "2024-05-30 20:16:56,530 Model Parameter Configuration:\n",
      "2024-05-30 20:16:56,566 Parameter gamma: torch.Size([1]), require_grad = False\n",
      "2024-05-30 20:16:56,566 Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "2024-05-30 20:16:56,577 Parameter entity_embedding: torch.Size([45158, 200]), require_grad = True\n",
      "2024-05-30 20:16:56,577 Parameter relation_embedding: torch.Size([24, 200]), require_grad = True\n",
      "C:\\Users\\ndeak\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "2024-05-30 20:17:34,246 Randomly Initializing TransE Model...\n",
      "2024-05-30 20:17:34,246 Start Training...\n",
      "2024-05-30 20:17:34,264 init_step = 0\n",
      "2024-05-30 20:17:34,264 batch_size = 1024\n",
      "2024-05-30 20:17:34,272 negative_adversarial_sampling = 0\n",
      "2024-05-30 20:17:34,284 hidden_dim = 200\n",
      "2024-05-30 20:17:34,284 gamma = 12.000000\n",
      "2024-05-30 20:17:34,316 negative_adversarial_sampling = False\n",
      "2024-05-30 20:17:34,339 learning_rate = 0\n",
      "C:\\Users\\ndeak\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 276\u001b[0m\n\u001b[0;32m    273\u001b[0m args \u001b[38;5;241m=\u001b[39m Args()\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# Run the main function with these arguments\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 215\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m#training loop initialise from initial stem to maximum step\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(init_step, args\u001b[38;5;241m.\u001b[39mmax_steps):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m#Trianing step: calls the training model in a single step and return the log metrics\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m     log \u001b[38;5;241m=\u001b[39m \u001b[43mkge_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkge_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     training_logs\u001b[38;5;241m.\u001b[39mappend(log)\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m#learning rate adjustment\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\GNN\\model.py:260\u001b[0m, in \u001b[0;36mKGEModel.train_step\u001b[1;34m(model, optimizer, train_iterator, args)\u001b[0m\n\u001b[0;32m    256\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    258\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 260\u001b[0m positive_sample, negative_sample, subsampling_weight, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mcuda:\n\u001b[0;32m    263\u001b[0m     positive_sample \u001b[38;5;241m=\u001b[39m positive_sample\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\GNN\\dataloader.py:174\u001b[0m, in \u001b[0;36mBidirectionalOneShotIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator_head)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_tail\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\GNN\\dataloader.py:183\u001b[0m, in \u001b[0;36mBidirectionalOneShotIterator.one_shot_iterator\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03mTransform a PyTorch Dataloader into python iterator\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import KGEModel\n",
    "from dataloader import TrainDataset, BidirectionalOneShotIterator\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cuda = False\n",
    "        self.do_train = True\n",
    "        self.do_valid = True\n",
    "        self.do_test = True\n",
    "        self.evaluate_train = False\n",
    "        self.countries = False\n",
    "        self.regions = None\n",
    "        self.data_path = 'data/FB15k'\n",
    "        self.model = 'TransE'\n",
    "        self.double_entity_embedding = False\n",
    "        self.double_relation_embedding = False\n",
    "        self.negative_sample_size = 128\n",
    "        self.hidden_dim = 200\n",
    "        self.gamma = 12.0\n",
    "        self.negative_adversarial_sampling = False\n",
    "        self.adversarial_temperature = 1.0\n",
    "        self.batch_size = 1024\n",
    "        self.regularization = 0.0\n",
    "        self.test_batch_size = 4\n",
    "        self.uni_weight = False\n",
    "        self.learning_rate = 0.001\n",
    "        self.cpu_num = 10\n",
    "        self.init_checkpoint = None\n",
    "        self.save_path = 'models/TransE_FB15k'\n",
    "        self.max_steps = 2000\n",
    "        self.warm_up_steps = None\n",
    "        self.save_checkpoint_steps = 1000\n",
    "        self.valid_steps = 1000\n",
    "        self.log_steps = 100\n",
    "        self.test_log_steps = 1000\n",
    "        self.nentity = 0\n",
    "        self.nrelation = 0\n",
    "\n",
    "def override_config(args):\n",
    "    pass  # implement based on your script\n",
    "\n",
    "def save_model(model, optimizer, save_variable_list, args):\n",
    "    pass  # implement based on your script\n",
    "\n",
    "def read_triple(file_path, entity2id, relation2id):\n",
    "    triples = []\n",
    "    with open(file_path) as fin:\n",
    "        for line in fin:\n",
    "            head, relation, tail = line.strip().split('\\t')\n",
    "            triples.append((entity2id[head], relation2id[relation], entity2id[tail]))\n",
    "    return triples\n",
    "\n",
    "def set_logger(args):\n",
    "    log_file = os.path.join(args.save_path or args.init_checkpoint, 'train.log')\n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s %(message)s',\n",
    "        level=logging.INFO,\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def log_metrics(mode, step, metrics):\n",
    "    for metric in metrics:\n",
    "        logging.info('%s %s at step %d: %f' % (mode, metric, step, metrics[metric]))\n",
    "\n",
    "def main(args):\n",
    "    if (not args.do_train) and (not args.do_valid) and (not args.do_test):\n",
    "        raise ValueError('One of train/val/test mode must be chosen.')\n",
    "    \n",
    "    if args.init_checkpoint:\n",
    "        override_config(args)\n",
    "    elif args.data_path is None:\n",
    "        raise ValueError('One of init_checkpoint/data_path must be chosen.')\n",
    "\n",
    "    if args.do_train and args.save_path is None:\n",
    "        raise ValueError('Where do you want to save your trained model?')\n",
    "    \n",
    "    if args.save_path and not os.path.exists(args.save_path):\n",
    "        os.makedirs(args.save_path)\n",
    "    \n",
    "    set_logger(args)\n",
    "    \n",
    "    with open(os.path.join(args.data_path, 'entities.dict')) as fin:\n",
    "        entity2id = dict()\n",
    "        for line in fin:\n",
    "            eid, entity = line.strip().split('\\t')\n",
    "            entity2id[entity] = int(eid)\n",
    "\n",
    "    with open(os.path.join(args.data_path, 'relations.dict')) as fin:\n",
    "        relation2id = dict()\n",
    "        for line in fin:\n",
    "            rid, relation = line.strip().split('\\t')\n",
    "            relation2id[relation] = int(rid)\n",
    "    \n",
    "    if args.countries:\n",
    "        regions = list()\n",
    "        with open(os.path.join(args.data_path, 'regions.list')) as fin:\n",
    "            for line in fin:\n",
    "                region = line.strip()\n",
    "                regions.append(entity2id[region])\n",
    "        args.regions = regions\n",
    "\n",
    "    nentity = len(entity2id)\n",
    "    nrelation = len(relation2id)\n",
    "    \n",
    "    args.nentity = nentity\n",
    "    args.nrelation = nrelation\n",
    "    \n",
    "    logging.info('Model: %s' % args.model)\n",
    "    logging.info('Data Path: %s' % args.data_path)\n",
    "    logging.info('#entity: %d' % nentity)\n",
    "    logging.info('#relation: %d' % nrelation)\n",
    "    \n",
    "    train_triples = read_triple(os.path.join(args.data_path, 'train.txt'), entity2id, relation2id)\n",
    "    logging.info('#train: %d' % len(train_triples))\n",
    "    valid_triples = read_triple(os.path.join(args.data_path, 'valid.txt'), entity2id, relation2id)\n",
    "    logging.info('#valid: %d' % len(valid_triples))\n",
    "    test_triples = read_triple(os.path.join(args.data_path, 'test.txt'), entity2id, relation2id)\n",
    "    logging.info('#test: %d' % len(test_triples))\n",
    "    \n",
    "    all_true_triples = train_triples + valid_triples + test_triples\n",
    "    \n",
    "    kge_model = KGEModel(\n",
    "        model_name=args.model,\n",
    "        nentity=nentity,\n",
    "        nrelation=nrelation,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        gamma=args.gamma,\n",
    "        double_entity_embedding=args.double_entity_embedding,\n",
    "        double_relation_embedding=args.double_relation_embedding\n",
    "    )\n",
    "    \n",
    "    logging.info('Model Parameter Configuration:')\n",
    "    for name, param in kge_model.named_parameters():\n",
    "        logging.info('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\n",
    "\n",
    "    if args.cuda:\n",
    "        kge_model = kge_model.cuda()\n",
    "    \n",
    "    if args.do_train:\n",
    "        train_dataloader_head = DataLoader(\n",
    "            TrainDataset(train_triples, nentity, nrelation, args.negative_sample_size, 'head-batch'), \n",
    "            batch_size=args.batch_size*2,\n",
    "            shuffle=True, \n",
    "            num_workers=max(1, args.cpu_num//2),\n",
    "            collate_fn=TrainDataset.collate_fn\n",
    "        )\n",
    "        \n",
    "        train_dataloader_tail = DataLoader(\n",
    "            TrainDataset(train_triples, nentity, nrelation, args.negative_sample_size, 'tail-batch'), \n",
    "            batch_size=args.batch_size*2,\n",
    "            shuffle=True, \n",
    "            num_workers=max(1, args.cpu_num//2),\n",
    "            collate_fn=TrainDataset.collate_fn\n",
    "        )\n",
    "        \n",
    "        train_iterator = BidirectionalOneShotIterator(train_dataloader_head, train_dataloader_tail)\n",
    "        \n",
    "        current_learning_rate = args.learning_rate\n",
    "        optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, kge_model.parameters()), \n",
    "            lr=current_learning_rate\n",
    "        )\n",
    "        if args.warm_up_steps:\n",
    "            warm_up_steps = args.warm_up_steps\n",
    "        else:\n",
    "            warm_up_steps = args.max_steps // 2\n",
    "\n",
    "    if args.init_checkpoint:\n",
    "        logging.info('Loading checkpoint %s...' % args.init_checkpoint)\n",
    "        checkpoint = torch.load(os.path.join(args.init_checkpoint, 'checkpoint'))\n",
    "        init_step = checkpoint['step']\n",
    "        kge_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if args.do_train:\n",
    "            current_learning_rate = checkpoint['current_learning_rate']\n",
    "            warm_up_steps = checkpoint['warm_up_steps']\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    else:\n",
    "        logging.info('Randomly Initializing %s Model...' % args.model)\n",
    "        init_step = 0\n",
    "\n",
    "    #Training loop\n",
    "    step = init_step\n",
    "    #logging initial parameters\n",
    "    logging.info('Start Training...')\n",
    "    logging.info('init_step = %d' % init_step)\n",
    "    logging.info('batch_size = %d' % args.batch_size)\n",
    "    logging.info('negative_adversarial_sampling = %d' % args.negative_adversarial_sampling)\n",
    "    logging.info('hidden_dim = %d' % args.hidden_dim)\n",
    "    logging.info('gamma = %f' % args.gamma)\n",
    "    logging.info('negative_adversarial_sampling = %s' % str(args.negative_adversarial_sampling))\n",
    "    if args.negative_adversarial_sampling:\n",
    "        logging.info('adversarial_temperature = %f' % args.adversarial_temperature)\n",
    "\n",
    "    #Checking training condition\n",
    "    if args.do_train:\n",
    "        logging.info('learning_rate = %d' % current_learning_rate)\n",
    "\n",
    "        training_logs = []\n",
    "\n",
    "        #training loop initialise from initial stem to maximum step\n",
    "        for step in range(init_step, args.max_steps):\n",
    "            #Trianing step: calls the training model in a single step and return the log metrics\n",
    "            log = kge_model.train_step(kge_model, optimizer, train_iterator, args)\n",
    "            \n",
    "            training_logs.append(log)\n",
    "            \n",
    "            #learning rate adjustment\n",
    "            if step >= warm_up_steps: #warm up steps should always be lower\n",
    "                current_learning_rate = current_learning_rate / 10\n",
    "                logging.info('Change learning_rate to %f at step %d' % (current_learning_rate, step))\n",
    "                #creates a new adam optimizer with the new leatning rate\n",
    "                optimizer = torch.optim.Adam(\n",
    "                    filter(lambda p: p.requires_grad, kge_model.parameters()), \n",
    "                    lr=current_learning_rate\n",
    "                )\n",
    "                warm_up_steps = warm_up_steps * 3\n",
    "            #save checkpoints\n",
    "            if step % args.save_checkpoint_steps == 0:\n",
    "                save_variable_list = {\n",
    "                    'step': step, \n",
    "                    'current_learning_rate': current_learning_rate,\n",
    "                    'warm_up_steps': warm_up_steps\n",
    "                }\n",
    "                save_model(kge_model, optimizer, save_variable_list, args)\n",
    "                \n",
    "            if step % args.log_steps == 0:\n",
    "                metrics = {}\n",
    "                for metric in training_logs[0].keys():\n",
    "                    metrics[metric] = sum([log[metric] for log in training_logs])/len(training_logs)\n",
    "                log_metrics('Training average', step, metrics)\n",
    "                training_logs = []\n",
    "                \n",
    "            if args.do_valid and step % args.valid_steps == 0:\n",
    "                logging.info('Evaluating on Valid Dataset...')\n",
    "                metrics = kge_model.test_step(kge_model, valid_triples, all_true_triples, args)\n",
    "                log_metrics('Valid', step, metrics)\n",
    "        \n",
    "        save_variable_list = {\n",
    "            'step': step, \n",
    "            'current_learning_rate': current_learning_rate,\n",
    "            'warm_up_steps': warm_up_steps\n",
    "        }\n",
    "        save_model(kge_model, optimizer, save_variable_list, args)\n",
    "        \n",
    "    if args.do_valid:\n",
    "        logging.info('Evaluating on Valid Dataset...')\n",
    "        metrics = kge_model.test_step(kge_model, valid_triples, all_true_triples, args)\n",
    "        log_metrics('Valid', step, metrics)\n",
    "    \n",
    "    if args.do_test:\n",
    "        logging.info('Evaluating on Test Dataset...')\n",
    "        metrics = kge_model.test_step(kge_model, test_triples, all_true_triples, args)\n",
    "        log_metrics('Test', step, metrics)\n",
    "    \n",
    "    if args.evaluate_train:\n",
    "        logging.info('Evaluating on Training Dataset...')\n",
    "        metrics = kge_model.test_step(kge_model, train_triples, all_true_triples, args)\n",
    "        log_metrics('Test', step, metrics)\n",
    "\n",
    "# Initialize the argument class\n",
    "args = Args()\n",
    "\n",
    "# Run the main function with these arguments\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391a025c-e193-4f84-bdea-4f1834c9d28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "cpu_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
